{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkrQ26eXaYDW",
    "outputId": "6575df17-fb18-4cb6-fab9-2f57e0ebbbca"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Conv1D, Flatten, AveragePooling1D\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "drive.mount(\"/content/drive\", force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtKqbhLXbaic"
   },
   "outputs": [],
   "source": [
    "url =  \"/content/drive/MyDrive/datafile/filtered_data.csv\"\n",
    "filtered_df = pd.read_csv(url,engine='python',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TW4jaAnMzO6X"
   },
   "outputs": [],
   "source": [
    "####################### Data Creation for Linear Round #######################\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the filtered data CSV file\n",
    "#filtered_df = pd.read_csv(\"filtered_data.csv\")\n",
    "\n",
    "# Drop columns 1 to 16 and 33 to 48\n",
    "filtered_df1 = filtered_df.drop(filtered_df.columns[0:16], axis=1)\n",
    "filtered_df = filtered_df1.drop(filtered_df1.columns[16:33], axis=1)\n",
    "\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "filtered_df.to_csv(\"filtered_data_real_cipher.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "r4Fg3KT9MgNP",
    "outputId": "8ef726af-ab2a-49d5-cbee-ed80fb84d0be"
   },
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7TqQurXh09r"
   },
   "outputs": [],
   "source": [
    "%run '/content/drive/MyDrive/Colab Notebooks/salsa_encryption.ipynb'  # If you want to run the entire notebook\n",
    "# OR\n",
    "#from Salsa_dataset_creation import encrypt  # If you want to import only a specific function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1X36S_loMrww"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "listoflists = []\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Read the CSV file\n",
    "df = pd.read_csv('filtered_data_real_cipher.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "24bnfKMMMuL6",
    "outputId": "d2305434-e78d-4ae1-f22d-4a090d3c5588"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKSBfeU4h03L"
   },
   "outputs": [],
   "source": [
    "############## Encryption for linear trail #########################\n",
    "\n",
    "\n",
    "# Step 2: Process each row\n",
    "i=0\n",
    "for index, row in df.iterrows():\n",
    "    result = []\n",
    "    i=i+1\n",
    "    # Extract row as an array of integers\n",
    "    P = row.values.astype(int)[:16]\n",
    "    #print(P)\n",
    "\n",
    "    #l1 = []\n",
    "    # Step 3: Apply the 'real_plain' function\n",
    "    result = real_plain(P, 2, 1)     # Number of encryption round #Odd or even ( ### 0 for column round and 1 for row)\n",
    "    #print(result)\n",
    "    listoflists.append(result)\n",
    "\n",
    "\n",
    "header = [\n",
    "          'C1_0','C1_1','C1_2','C1_3','C1_4','C1_5','C1_6','C1_7','C1_8','C1_9','C1_10','C1_11','C1_12','C1_13','C1_14','C1_15',\n",
    "          'Label']\n",
    "import csv\n",
    "#print(listoflists)\n",
    "\n",
    "filename = 'linear_encryption_data.csv'\n",
    "with open(filename, 'w', newline=\"\") as file:\n",
    "    csvwriter = csv.writer(file) #  create a csvwriter object\n",
    "    csvwriter.writerow(header) #  write the header\n",
    "    csvwriter.writerows(listoflists) #  write the rest of the data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DthJYjA3wYW-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def to_32bit_binary(num):\n",
    "    return f\"{num:032b}\"\n",
    "\n",
    "def extract_bit(num, bit):\n",
    "    return int(to_32bit_binary(num)[31 - bit])\n",
    "\n",
    "# Read the CSV files\n",
    "df_before_round = pd.read_csv('filtered_data_real_cipher.csv')\n",
    "df_after_round = pd.read_csv('linear_encryption_data.csv')\n",
    "\n",
    "# Initialize the label column for the round dataset\n",
    "df_after_round['Label'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwI9S6ol3q-b"
   },
   "source": [
    "1 round Linear trail after 3 round :\n",
    "-----------\n",
    "\n",
    "$\\Delta^0_{15,18},$\n",
    "Correlation: 0\n",
    "\n",
    "round:0  -->    \"$\\Delta^0_{15,18},$ \"\n",
    "\n",
    "round:1  -->    \"$\\Delta^1_{13,0},$ $\\Delta^1_{14,0},$ $\\Delta^1_{15,18},$ \"\n",
    "\n",
    "----------\n",
    "\n",
    "$\\Delta^0_{12,7},$\n",
    "$\\Delta^0_{14,0},$\n",
    "$\\Delta^0_{15,0},$\n",
    "\n",
    "Correlation: 0\n",
    "\n",
    "round:0  -->    \"$\\Delta^0_{12,7},$ $\\Delta^0_{14,0},$ $\\Delta^0_{15,0},$ \"\n",
    "\n",
    "round:1  -->    \"$\\Delta^1_{12,7},$ \"\n",
    "\n",
    "\n",
    "Two round linear trail after 3 round:\n",
    "---------\n",
    "$\\Delta^0_{12,7},$\n",
    "$\\Delta^0_{14,0},$\n",
    "$\\Delta^0_{15,0},$\n",
    "\n",
    "Correlation: 1\n",
    "\n",
    "round:0  -->    \"$\\Delta^0_{12,7},$ $\\Delta^0_{14,0},$ $\\Delta^0_{15,0},$ \"\n",
    "\n",
    "round:1  -->    \"$\\Delta^1_{12,7},$ \"\n",
    "\n",
    "round:2  -->    \"$\\Delta^2_{4,26},$ $\\Delta^2_{8,26},$ $\\Delta^2_{8,25},$ $\\Delta^2_{12,7},$ \"\n",
    "\n",
    "------\n",
    "\n",
    "$\\Delta^0_{13,9},$\n",
    "$\\Delta^0_{15,0},$\n",
    "\n",
    "Correlation: 2\n",
    "\n",
    "round:0  -->    \"$\\Delta^0_{13,9},$ $\\Delta^0_{15,0},$ \"\n",
    "\n",
    "round:1  -->    \"$\\Delta^1_{12,0},$ $\\Delta^1_{13,9},$ \"\n",
    "\n",
    "round:2  -->    \"$\\Delta^2_{1,14},$ $\\Delta^2_{1,13},$ $\\Delta^2_{4,19},$ $\\Delta^2_{5,0},$ $\\Delta^2_{8,19},$ $\\Delta^2_{8,18},$ $\\Delta^2_{9,0},$ $\\Delta^2_{12,0},$ $\\Delta^2_{13,14},$ $\\Delta^2_{13,9},$ \"\n",
    "\n",
    "\n",
    "Three round linear trail after 3 round:\n",
    "---------\n",
    "$\\Delta^0_{12,7},$\n",
    "$\\Delta^0_{14,0},$\n",
    "$\\Delta^0_{15,0},$\n",
    "\n",
    "Correlation: 6\n",
    "\n",
    "round:0  -->    \"$\\Delta^0_{12,7},$ $\\Delta^0_{14,0},$ $\\Delta^0_{15,0},$ \"\n",
    "\n",
    "round:1  -->    \"$\\Delta^1_{12,7},$ \"\n",
    "\n",
    "round:2  -->    \"$\\Delta^2_{4,26},$ $\\Delta^2_{8,26},$ $\\Delta^2_{8,25},$ $\\Delta^2_{12,7},$ \"\n",
    "\n",
    "round:3  -->    \"$\\Delta^3_{4,26},$ $\\Delta^3_{6,13},$ $\\Delta^3_{6,12},$ $\\Delta^3_{7,13},$ $\\Delta^3_{8,31},$ $\\Delta^3_{8,30},$ $\\Delta^3_{8,26},$ $\\Delta^3_{8,25},$ $\\Delta^3_{9,31},$ $\\Delta^3_{10,17},$ $\\Delta^3_{11,17},$ $\\Delta^3_{12,19},$ $\\Delta^3_{12,18},$ $\\Delta^3_{12,7},$ $\\Delta^3_{13,19},$ $\\Delta^3_{13,14},$ $\\Delta^3_{14,14},$ $\\Delta^3_{14,13},$ $\\Delta^3_{14,0},$ $\\Delta^3_{15,0},$ \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLqpKPRz1QWm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzHcNuGZh0t4"
   },
   "outputs": [],
   "source": [
    "############## Labeling as per the linear condition for 2 round  ###########################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def to_32bit_binary(num):\n",
    "    return f\"{num:032b}\"\n",
    "\n",
    "def extract_bit(num, bit):\n",
    "    return int(to_32bit_binary(num)[31 - bit])\n",
    "\n",
    "# Read the CSV files\n",
    "df_before_round = pd.read_csv('filtered_data_real_cipher.csv')\n",
    "df_after_round = pd.read_csv('linear_encryption_data.csv')\n",
    "\n",
    "# Initialize the label column for the 5-round dataset\n",
    "df_after_round['Label'] = 0\n",
    "\n",
    "# for i, row in df_after_round.iterrows():\n",
    "#     # Get the 7th bit of C1_4 from the 5-round data\n",
    "#     C1_4_7_5_round = extract_bit(row['C1_4'], 7)\n",
    "\n",
    "#     # Get the 7th bit of C1_4, 0th bit of C1_0, and 0th bit of C1_12 from the 4-round data\n",
    "#     C1_4_7_4_round = extract_bit(df_before_round.loc[i, 'C1_4'], 7)\n",
    "#     C1_0_0_4_round = extract_bit(df_before_round.loc[i, 'C1_0'], 0)\n",
    "#     C1_12_0_4_round = extract_bit(df_before_round.loc[i, 'C1_12'], 0)\n",
    "\n",
    "#     # Calculate the XOR result\n",
    "#     xor_result = C1_4_7_4_round ^ C1_0_0_4_round ^ C1_12_0_4_round\n",
    "\n",
    "#     # Check the condition and update the label\n",
    "#     if C1_4_7_5_round == xor_result:\n",
    "#         df_after_round.at[i, 'Label'] = 1\n",
    "#     else:\n",
    "#         df_after_round.at[i, 'Label'] = 0\n",
    "\n",
    "\n",
    "\n",
    "for i, row in df_after_round.iterrows():\n",
    "    # Get the bits of after round data\n",
    "    after_1_14 = extract_bit(row['C1_1'], 14)\n",
    "    after_1_13 = extract_bit(row['C1_1'], 13)\n",
    "    after_4_19 = extract_bit(row['C1_4'], 19)\n",
    "    after_5_0 = extract_bit(row['C1_5'], 0)\n",
    "    after_8_19 = extract_bit(row['C1_8'], 19)\n",
    "    after_8_18 = extract_bit(row['C1_8'], 18)\n",
    "    after_9_0 = extract_bit(row['C1_9'], 0)\n",
    "    after_12_0 = extract_bit(row['C1_12'], 0)\n",
    "    after_13_14 = extract_bit(row['C1_13'], 14)\n",
    "    after_13_9 = extract_bit(row['C1_13'], 9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    after_xor = (after_1_14 ^ after_1_13^ after_4_19^ after_5_0^ after_8_19^ after_8_18^ after_9_0^ after_12_0^ after_13_14^ after_13_9)\n",
    "\n",
    "    # Get the bits of  before round data\n",
    "    before_13_9 = extract_bit(df_before_round.loc[i, 'C1_13'], 9)\n",
    "    before_15_0 = extract_bit(df_before_round.loc[i, 'C1_15'], 0)\n",
    "\n",
    "\n",
    "\n",
    "    before_xor = before_13_9 ^ before_15_0\n",
    "\n",
    "\n",
    "\n",
    "    # Check the condition and update the label\n",
    "    if after_xor == before_xor:\n",
    "        df_after_round.at[i, 'Label'] = 1\n",
    "    else:\n",
    "        df_after_round.at[i, 'Label'] = 0\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df_after_round.to_csv('after_linear_trail_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "MN8FRmi9Ol85",
    "outputId": "aee8a236-0bbd-4582-8e5e-cfe1e0819254"
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('after_linear_trail_data.csv')\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjEjR7QrOmfe"
   },
   "source": [
    "**Model for the single/ double round Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQHQcxwBOl59",
    "outputId": "4d910e4e-3ffc-4631-bc82-e58d62a2e0f0"
   },
   "outputs": [],
   "source": [
    "single_cipher = \"after_linear_trail_data.csv\"\n",
    "\n",
    "feature =[\n",
    "       'C1_0','C1_1','C1_2', 'C1_3','C1_4','C1_5','C1_6', 'C1_7','C1_8','C1_9','C1_10', 'C1_11','C1_12','C1_13','C1_14', 'C1_15',\n",
    " 'Label']\n",
    "\n",
    "\n",
    "\n",
    "data_set=pd.read_csv( single_cipher ,names = feature , engine='python',encoding='ISO-8859-1')\n",
    "\n",
    "data_set1=data_set.iloc[1:]\n",
    "\n",
    "\n",
    "\n",
    "c0 =data_set1['C1_0'].to_numpy()\n",
    "c0 = c0.astype(np.uint32)\n",
    "\n",
    "c1 =data_set1['C1_1'].to_numpy()\n",
    "c1 = c1.astype(np.uint32)\n",
    "\n",
    "c2 =data_set1['C1_2'].to_numpy()\n",
    "c2 = c2.astype(np.uint32)\n",
    "\n",
    "c3 =data_set1['C1_3'].to_numpy()\n",
    "c3 = c3.astype(np.uint32)\n",
    "\n",
    "c4 =data_set1['C1_4'].to_numpy()\n",
    "c4 = c4.astype(np.uint32)\n",
    "\n",
    "c5 =data_set1['C1_5'].to_numpy()\n",
    "c5 = c5.astype(np.uint32)\n",
    "\n",
    "c6 =data_set1['C1_6'].to_numpy()\n",
    "c6 = c6.astype(np.uint32)\n",
    "\n",
    "c7 =data_set1['C1_7'].to_numpy()\n",
    "c7 = c7.astype(np.uint32)\n",
    "\n",
    "c8 =data_set1['C1_8'].to_numpy()\n",
    "c8 = c8.astype(np.uint32)\n",
    "\n",
    "c9 =data_set1['C1_9'].to_numpy()\n",
    "c9 = c9.astype(np.uint32)\n",
    "\n",
    "c10 =data_set1['C1_10'].to_numpy()\n",
    "c10 = c10.astype(np.uint32)\n",
    "\n",
    "c11 =data_set1['C1_11'].to_numpy()\n",
    "c11 = c11.astype(np.uint32)\n",
    "\n",
    "c12 =data_set1['C1_12'].to_numpy()\n",
    "c12 = c12.astype(np.uint32)\n",
    "\n",
    "c13 =data_set1['C1_13'].to_numpy()\n",
    "c13 = c13.astype(np.uint32)\n",
    "\n",
    "c14 =data_set1['C1_14'].to_numpy()\n",
    "c14 = c14.astype(np.uint32)\n",
    "\n",
    "c15 =data_set1['C1_15'].to_numpy()\n",
    "c15 = c15.astype(np.uint32)\n",
    "\n",
    "\n",
    "C1 = [  c0, c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15 ]\n",
    "\n",
    "\n",
    "\n",
    "# C = {i: data_set1[f'C1_{i}'].to_numpy(dtype=np.uint32) for i in range(16)}\n",
    "\n",
    "\n",
    "# C1 = [ [C[i] for i in range(16)] ]\n",
    "\n",
    "\n",
    "Y1 = data_set1['Label'].to_numpy()\n",
    "Y1 = Y1.astype(np.int32)\n",
    "\n",
    "\n",
    "def WORD_SIZE():\n",
    "  return(32);\n",
    "def convert_to_binary(arr):\n",
    "  X1 = np.zeros((16 * WORD_SIZE(),len(arr[0])),dtype=np.uint8);\n",
    "  for i in range(16 * WORD_SIZE()):\n",
    "    index = i // WORD_SIZE();\n",
    "    offset = WORD_SIZE() - (i % WORD_SIZE()) - 1;\n",
    "    X1[i] = ((arr[index]) >> offset) & 1;\n",
    "\n",
    "  #print(X1)\n",
    "  X1 = X1.transpose();\n",
    "\n",
    "  return(X1);\n",
    "\n",
    "\n",
    "X1 =convert_to_binary(C1)\n",
    "\n",
    "print(len(X1[0]))\n",
    "\n",
    "#Split the data into train test set#\n",
    "\n",
    "seed=9\n",
    "np.random.seed(seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=0.50,random_state=seed)\n",
    "#X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.50,random_state=seed)\n",
    "\n",
    "\n",
    "print(len(X_train),len(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdSdl-0uNC_d"
   },
   "outputs": [],
   "source": [
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q61fs7uCHqXl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vwct_N8JHqUW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0BDJZp5MvL7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G2y_pCO2MwKB",
    "outputId": "569899c9-44b3-4232-91fc-77f7eb31d1aa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define Custom Callback for Learning Rate Logging\n",
    "class LearningRateLogger(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        print(f\"Epoch {epoch + 1}: Learning Rate = {lr:.6f}\")\n",
    "\n",
    "# Load Data (Replace with your dataset)\n",
    "##X_train, X_test, y_train, y_test = ...  # Load or preprocess your dataset\n",
    "\n",
    "# Define Class Weights (if applicable)\n",
    "class_weights_dict = {0: 1.0, 1: 2.0}  # Adjust based on your dataset\n",
    "\n",
    "# Define the Model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(1, activation='sigmoid')  # Adjust activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define Callbacks\n",
    "lr_logger = LearningRateLogger()\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    X_train, y_train, class_weight=class_weights_dict,\n",
    "    epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
    "    callbacks=[lr_logger, lr_scheduler, early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1t_oW-zMwGJ",
    "outputId": "74140be3-9be5-4c71-b86d-a506cdbad9e3"
   },
   "outputs": [],
   "source": [
    "final_val_accuracy = history.history['val_accuracy'][-1]  # Last epoch's validation accuracy\n",
    "print(f\"\\nFinal Validation Accuracy: {final_val_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate Model on Test Set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSB7HaB42fNL",
    "outputId": "80ccabca-bb86-45b2-dc4e-f871699d5437"
   },
   "outputs": [],
   "source": [
    "# make probability predictions with the model\n",
    "predictions = model.predict(X_test)\n",
    "# round predictions\n",
    "#rounded = [(x[0]) for x in predictions]\n",
    "\n",
    "\n",
    "prd=[]\n",
    "for i in range(len(predictions)):\n",
    "  if predictions[i]>0.5:\n",
    "    prd.append(1)\n",
    "    #print(predictions)\n",
    "  else:\n",
    "    prd.append(0)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "matrix = metrics.confusion_matrix(y_test[:len(prd)], prd)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o58yUC-m2fJV",
    "outputId": "2b09ac3a-5347-4697-b887-8c89e3a42d1a"
   },
   "outputs": [],
   "source": [
    "TP=matrix[0][0]\n",
    "FN=matrix[0][1]\n",
    "FP=matrix[1][0]\n",
    "TN=matrix[1][1]\n",
    "TPR=TP/(TP+FN)\n",
    "print(TPR)\n",
    "TNR=TN/(TN+FP)\n",
    "print(TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRUbiVHjb9AG"
   },
   "outputs": [],
   "source": [
    "########################################### END ###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BhlzAiXb85t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZVWcRnUb82C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
